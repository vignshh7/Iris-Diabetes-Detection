# Diabetes Detection from Iris Images

## Project Overview
This system detects diabetes through non-invasive iris image analysis using computer vision and deep learning. The project employs a two-stage approach: iris segmentation followed by pancreatic region classification to identify diabetic patterns in eye images.

## ğŸ“ Dataset Structure

```
eye_project/
â”œâ”€â”€ ğŸ“ dataset/                           # Main dataset directory
â”‚   â”œâ”€â”€ ğŸ“ data/                          # Raw image data
â”‚   â”‚   â”œâ”€â”€ ğŸ“ control/                   # Control (healthy) subject images
â”‚   â”‚   â”‚   â”œâ”€â”€ patient_1_left.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ patient_1_right.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ... (52 patients Ã— 2 eyes)
â”‚   â”‚   â””â”€â”€ ğŸ“ diabetic/                  # Diabetic subject images
â”‚   â”‚       â”œâ”€â”€ patient_53_left.jpg
â”‚   â”‚       â”œâ”€â”€ patient_53_right.jpg
â”‚   â”‚       â””â”€â”€ ... (76 patients Ã— 2 eyes)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ masks/                         # Manual annotations for training
â”‚   â”‚   â”œâ”€â”€ ğŸ“ control/                   # Control iris masks
â”‚   â”‚   â””â”€â”€ ğŸ“ diabetic/                  # Diabetic iris masks
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ pancreatic_masks/              # Generated ROI masks
â”‚       â”œâ”€â”€ ğŸ“ control/                   # Control pancreatic region masks
â”‚       â””â”€â”€ ğŸ“ diabetic/                  # Diabetic pancreatic region masks
â”‚
â”œâ”€â”€ ğŸ“ models/                            # Trained model checkpoints
â”‚   â”œâ”€â”€ best_iris_model_3class.pth        # Iris segmentation model
â”‚   â”œâ”€â”€ best_f1_model_fold_1.pth          # Classification model fold 1
â”‚   â”œâ”€â”€ best_f1_model_fold_2.pth          # Classification model fold 2
â”‚   â”œâ”€â”€ best_f1_model_fold_3.pth          # Classification model fold 3
â”‚   â”œâ”€â”€ best_f1_model_fold_4.pth          # Classification model fold 4
â”‚   â””â”€â”€ best_f1_model_fold_5.pth          # Classification model fold 5
â”‚
â”œâ”€â”€ ğŸ“ src/                               # Source code directory
â”‚   â”œâ”€â”€ cnntrain.py                       # Classification training script
â”‚   â”œâ”€â”€ cnnpredict.py                     # Classification prediction script
â”‚   â”œâ”€â”€ maskstrain.py                     # Iris segmentation training
â”‚   â”œâ”€â”€ maskspredict.py                   # Iris mask generation
â”‚   â”œâ”€â”€ generate_masks.py                 # Pancreatic mask generation
â”‚   â”œâ”€â”€ metrices.py                       # Model evaluation
â”‚   â”œâ”€â”€ evaluate.py                       # Performance analysis
â”‚   â”œâ”€â”€ data_manager.py                   # Data splitting and management
â”‚   â””â”€â”€ visualize_results.py              # Result visualization
â”‚
â”œâ”€â”€ ğŸ“ results/                           # Output results
â”‚   â”œâ”€â”€ cross_validation_results.json     # CV performance metrics
â”‚   â”œâ”€â”€ prediction_results.csv            # Model predictions
â”‚   â””â”€â”€ evaluation_results.csv            # Test set evaluation
â”‚
â”œâ”€â”€ ğŸ“ performance_analysis/              # Performance analytics
â”‚   â”œâ”€â”€ ğŸ“ confusion_matrices/            # Confusion matrix plots
â”‚   â”œâ”€â”€ ğŸ“ metrics/                       # Performance metrics
â”‚   â””â”€â”€ ğŸ“ sample_results/                # Sample predictions
â”‚
â”œâ”€â”€ config.py                            # Centralized configuration
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ data_split_info.json                # Train/val/test splits
â””â”€â”€ README.md                           # This documentation
```

### Dataset Characteristics
- **Total Patients**: 128 (52 control, 76 diabetic)
- **Images per Patient**: 2 (left eye, right eye)
- **Image Format**: JPEG
- **Resolution**: Variable (auto-resized to 128Ã—128 for training)
- **Channels**: RGB color images
- **Annotations**: Manual iris segmentation masks for training

## ğŸ—‚ï¸ File Usage and Purpose

### Core Training Files

#### `src/cnntrain.py` - Classification Model Training
- **Purpose**: Train diabetic classification models using 5-fold cross-validation
- **Input**: Multi-channel eye images (RGB + Gray + HSV + LAB + spatial mask attention)
- **Architecture**: Custom CNN with Squeeze-and-Excitation blocks and GroupNorm
- **Output**: 5 trained model checkpoints (one per fold)
- **Key Features**:
  - Early stopping with patience=8
  - Optimal threshold finding per fold
  - Spatial attention masking
  - Reproducible training with fixed seeds

#### `src/cnnpredict.py` - Classification Prediction
- **Purpose**: Generate predictions on test data using ensemble of trained models
- **Input**: Eye image pairs from test set
- **Process**: Load 5-fold models, ensemble predictions, apply optimal thresholds
- **Output**: CSV file with patient predictions and probabilities

#### `src/maskstrain.py` - Iris Segmentation Training
- **Purpose**: Train U-Net model for iris segmentation
- **Architecture**: U-Net with MobileNetV2 encoder
- **Input**: Eye images with manual iris annotations
- **Output**: Trained segmentation model (`best_iris_model_3class.pth`)

#### `src/maskspredict.py` - Iris Mask Generation
- **Purpose**: Generate iris segmentation masks for all images
- **Input**: Raw eye images from control/diabetic directories
- **Process**: Apply trained segmentation model
- **Output**: Binary iris masks saved to appropriate directories

### Data Management Files

#### `src/data_manager.py` - Data Splitting and Management
- **Purpose**: Handle train/validation/test splits with no data leakage
- **Features**:
  - Stratified patient-level splitting (not image-level)
  - Reproducible splits with fixed random seeds
  - K-fold cross-validation generation
  - Split information saving/loading

#### `src/generate_masks.py` - Pancreatic Region Mask Generation
- **Purpose**: Create pancreatic region masks from iris segmentations
- **Process**:
  - Analyze iris masks to find center and radius
  - Generate annular pancreatic region (40%-85% of iris radius)
  - Account for left/right eye anatomical differences
- **Output**: ROI masks for training and inference

### Evaluation Files

#### `src/metrices.py` - Model Evaluation
- **Purpose**: Calculate comprehensive performance metrics on test set
- **Metrics**: Accuracy, Precision, Recall, F1-Score, AUC-ROC, Sensitivity, Specificity
- **Output**: Detailed performance report and confusion matrix

#### `src/evaluate.py` - Performance Analysis
- **Purpose**: Generate detailed performance analysis and visualizations
- **Features**:
  - ROC curve analysis
  - Probability distribution plots
  - Cross-validation results visualization
  - Sample prediction analysis

#### `src/visualize_results.py` - Result Visualization
- **Purpose**: Create visual outputs showing predictions with original images
- **Features**:
  - Side-by-side original and segmented images
  - Prediction overlays with confidence scores
  - Color-preserved visualization with thin borders

### Configuration Files

#### `config.py` - Centralized Configuration
- **Purpose**: Single source of truth for all paths and parameters
- **Contains**:
  - Directory paths for data, models, results
  - Training hyperparameters
  - Model architecture settings
  - Device configuration (CPU/GPU)

#### `data_split_info.json` - Split Information
- **Purpose**: Store train/validation/test patient splits
- **Format**: JSON with patient IDs for each split
- **Ensures**: Reproducible data splits across runs

#### `requirements.txt` - Dependencies
- **Purpose**: Specify exact Python package versions
- **Key Packages**: PyTorch, OpenCV, Albumentations, scikit-learn, torchmetrics

## ğŸ”„ System Workflow and Flow

### Phase 1: Iris Segmentation Pipeline

#### Step 1: Data Preparation
```
Raw Eye Images â†’ Manual Annotations â†’ Training Dataset
â”œâ”€â”€ Load eye images from dataset/data/control/ and dataset/data/diabetic/
â”œâ”€â”€ Load corresponding manual annotations from annotations.csv
â”œâ”€â”€ Split data into train/validation sets (85%/15%)
â””â”€â”€ Apply data augmentation (rotation, flip, brightness/contrast)
```

#### Step 2: Segmentation Model Training
```
Training Images + Annotations â†’ U-Net Training â†’ Trained Model
â”œâ”€â”€ Initialize U-Net with MobileNetV2 encoder
â”œâ”€â”€ Train with Dice loss for binary segmentation
â”œâ”€â”€ Monitor validation loss with early stopping
â””â”€â”€ Save best model as best_iris_model_3class.pth
```

#### Step 3: Iris Mask Generation
```
All Images â†’ Trained Segmentation Model â†’ Iris Masks
â”œâ”€â”€ Load trained segmentation model
â”œâ”€â”€ Process all images in dataset directories
â”œâ”€â”€ Generate binary iris masks
â””â”€â”€ Save masks to test_results_masks/ directories
```

### Phase 2: Classification Pipeline

#### Step 4: ROI Extraction
```
Iris Masks â†’ Geometric Analysis â†’ Pancreatic Region Masks
â”œâ”€â”€ Analyze iris masks to find center and radius
â”œâ”€â”€ Generate annular pancreatic region masks
â”œâ”€â”€ Inner radius: 40% of iris radius
â”œâ”€â”€ Outer radius: 85% of iris radius
â””â”€â”€ Save ROI masks to dataset/pancreatic_masks/
```

#### Step 5: Data Splitting (Academic Rigor)
```
Patient Data â†’ Stratified Splitting â†’ Train/Val/Test Sets
â”œâ”€â”€ Patient-level stratified splitting (not image-level)
â”œâ”€â”€ Train: 60%, Validation: 20%, Test: 20%
â”œâ”€â”€ Ensure no patient appears in multiple splits
â”œâ”€â”€ Save split information for reproducibility
â””â”€â”€ Generate K-fold splits from train+validation data only
```

#### Step 6: Classification Training (5-Fold CV)
```
For each fold (1-5):
    â”œâ”€â”€ Multi-channel Feature Extraction:
    â”‚   â”œâ”€â”€ RGB channels (3)
    â”‚   â”œâ”€â”€ Grayscale channel (1)
    â”‚   â”œâ”€â”€ HSV channels (3)
    â”‚   â”œâ”€â”€ LAB channels (3)
    â”‚   â””â”€â”€ Spatial mask attention (applied, not concatenated)
    â”‚
    â”œâ”€â”€ Model Architecture:
    â”‚   â”œâ”€â”€ Custom CNN with SE-blocks
    â”‚   â”œâ”€â”€ GroupNorm for batch size stability
    â”‚   â”œâ”€â”€ Three convolutional blocks
    â”‚   â””â”€â”€ Binary classification output
    â”‚
    â”œâ”€â”€ Training Process:
    â”‚   â”œâ”€â”€ Focal loss for class imbalance
    â”‚   â”œâ”€â”€ AdamW optimizer (lr=1e-4)
    â”‚   â”œâ”€â”€ Early stopping (patience=8)
    â”‚   â”œâ”€â”€ Validation-based threshold optimization
    â”‚   â””â”€â”€ Save best model per fold
    â”‚
    â””â”€â”€ Output: best_f1_model_fold_X.pth
```

#### Step 7: Ensemble Prediction
```
Test Images â†’ Ensemble of 5 Models â†’ Final Predictions
â”œâ”€â”€ Load all 5 trained models
â”œâ”€â”€ Process left-right eye pairs
â”œâ”€â”€ Multi-channel feature extraction with spatial attention
â”œâ”€â”€ Average predictions across models
â”œâ”€â”€ Apply fold-specific optimal thresholds
â””â”€â”€ Generate final classification with confidence scores
```

#### Step 8: Performance Evaluation
```
Predictions + Ground Truth â†’ Comprehensive Analysis
â”œâ”€â”€ Calculate performance metrics (Accuracy, F1, AUC, etc.)
â”œâ”€â”€ Generate confusion matrix and ROC curves
â”œâ”€â”€ Analyze prediction confidence distributions
â”œâ”€â”€ Create visualizations with prediction overlays
â””â”€â”€ Save results for clinical validation
```

### Data Flow Architecture

```
Input: Raw Eye Images (JPG)
    â†“
[Phase 1: Iris Segmentation]
    â”œâ”€â”€ U-Net Training â†’ Iris Masks
    â””â”€â”€ ROI Extraction â†’ Pancreatic Masks
    â†“
[Phase 2: Classification]
    â”œâ”€â”€ Multi-channel Processing:
    â”‚   â”œâ”€â”€ RGB â†’ 3 channels
    â”‚   â”œâ”€â”€ Gray â†’ 1 channel
    â”‚   â”œâ”€â”€ HSV â†’ 3 channels
    â”‚   â”œâ”€â”€ LAB â†’ 3 channels
    â”‚   â””â”€â”€ Mask â†’ Spatial attention
    â”‚
    â”œâ”€â”€ Paired Eye Processing:
    â”‚   â””â”€â”€ Left + Right â†’ 20 total channels
    â”‚
    â”œâ”€â”€ 5-Fold Cross-Validation:
    â”‚   â”œâ”€â”€ Fold 1 â†’ Model 1
    â”‚   â”œâ”€â”€ Fold 2 â†’ Model 2
    â”‚   â”œâ”€â”€ Fold 3 â†’ Model 3
    â”‚   â”œâ”€â”€ Fold 4 â†’ Model 4
    â”‚   â””â”€â”€ Fold 5 â†’ Model 5
    â”‚
    â””â”€â”€ Ensemble Prediction:
        â”œâ”€â”€ Average 5 model outputs
        â”œâ”€â”€ Apply optimal thresholds
        â””â”€â”€ Generate final classification
    â†“
Output: Diabetic/Control Classification + Confidence Score
```

### Key Workflow Principles

1. **Academic Rigor**: No test set contamination - test data never seen during training
2. **Reproducibility**: Fixed random seeds and saved split information
3. **Medical Standard**: Patient-level splitting prevents data leakage
4. **Robust Training**: Early stopping prevents overfitting on small dataset
5. **Optimal Performance**: Validation-based threshold optimization per fold
6. **Ensemble Approach**: 5-model ensemble for improved stability
7. **Spatial Attention**: Mask-guided learning focuses on pancreatic regions

This workflow ensures scientifically sound results suitable for medical AI validation and potential clinical deployment.