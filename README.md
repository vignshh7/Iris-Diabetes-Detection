# ğŸ‘ï¸ Diabetes Detection from Iris Images

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)](https://opencv.org)

> **Advanced Computer Vision System for Non-Invasive Diabetes Detection through Iris Analysis**

## Overview

This project implements a comprehensive deep learning system for detecting diabetes mellitus from iris images using advanced computer vision techniques. The system employs a two-phase approach combining iris segmentation and diabetic pattern classification to achieve robust and accurate diabetes detection.

## ğŸ“‹ Table of Contents

- [Project Architecture](#project-architecture)
- [Dataset](#dataset)
- [Implementation Phases](#implementation-phases)
- [Model Architecture](#model-architecture)
- [Project Structure](#project-structure)
- [Installation & Setup](#installation--setup)
- [Usage Instructions](#usage-instructions)
- [Performance Analysis](#performance-analysis)
- [Results](#results)
- [Technical Specifications](#technical-specifications)
- [Contributing](#contributing)

## ğŸ—ï¸ Project Architecture

### Two-Phase Approach

**Phase 1: Iris Segmentation Model**
- **Objective**: Precise segmentation of iris regions from eye images
- **Model**: U-Net with MobileNetV2 encoder
- **Input**: RGB eye images (256Ã—256)
- **Output**: Binary masks highlighting iris regions
- **Training**: Manual binary masks with data augmentation

**Phase 2: Diabetic Pattern Classification**
- **Objective**: Classify diabetic vs. control subjects based on pancreatic region patterns
- **Model**: Custom CNN with Squeeze-and-Excitation blocks
- **Input**: Multi-channel feature representations (RGB, Grayscale, HSV, LAB, Mask)
- **Output**: Binary classification (Diabetic/Control)
- **Training**: 5-fold cross-validation with ensemble learning

## ğŸ“Š Dataset

### Image Specifications
- **Format**: JPEG images
- **Resolution**: Variable (resized to 256Ã—256 for segmentation, 128Ã—128 for classification)
- **Channels**: RGB
- **Eye Types**: Left and Right eye pairs
- **Classes**: Control and Diabetic subjects

### Dataset Composition
- **Training Images**: Located in `dataset/` directory
- **Control Subjects**: `dataset/control/`
- **Diabetic Subjects**: `dataset/diabetic/`
- **Test Images**: `dataset/testing/` and `dataset/testing1/`
- **Manual Masks**: `dataset/masks/` (for iris segmentation training)

### Annotations
- **Format**: CSV file with VGG Image Annotator format
- **File**: `annotations.csv`
- **Content**: Spatial coordinates for iris regions
- **Total Annotations**: 117 annotated images

## ğŸ”„ Implementation Phases

### Phase 1: Iris Segmentation

#### Step 1: Model Training (`maskstrain.py`)
```python
# Key Features:
- U-Net architecture with MobileNetV2 encoder
- Dice loss for binary segmentation
- Data augmentation (rotation, flip, brightness/contrast)
- Train/validation split: 85%/15%
- Model saved as: best_iris_model_3class.pth
```

#### Step 2: Mask Generation (`maskspredict.py`)
```python
# Inference Process:
- Load trained segmentation model
- Process control and diabetic image directories
- Generate binary masks for iris regions
- Save masks in test_results_masks/
```

### Phase 2: ROI Extraction and Classification

#### Step 3: Pancreatic Mask Generation (`pancreaticmasks.py`)
```python
# ROI Extraction:
- Use iris masks to identify iris center and radius
- Generate pancreatic region masks (annular region)
- Inner radius: 40% of iris radius
- Outer radius: 85% of iris radius
- Account for left/right eye differences
```

#### Step 4: Classification Training (`cnntrain.py`)
```python
# Training Features:
- 5-fold stratified cross-validation
- Multi-channel input (RGB + Gray + HSV + LAB + Mask)
- Custom CNN with SE blocks
- Focal loss for class imbalance
- Ensemble of 5 models (one per fold)
```

#### Step 5: Prediction (`cnnpredict.py`)
```python
# Prediction Process:
- Load ensemble of trained models
- Process left-right eye pairs
- Multi-channel feature extraction
- Ensemble averaging for final prediction
```

## ğŸ§  Model Architecture

### Iris Segmentation Model (U-Net)
```
Encoder: MobileNetV2 (ImageNet pretrained)
â”œâ”€â”€ Decoder: Upsampling blocks
â”œâ”€â”€ Skip connections for feature preservation
â”œâ”€â”€ Output: 1 channel (binary mask)
â””â”€â”€ Loss: Dice Loss
```

### Classification Model (Custom CNN)
```
Input: Multi-channel features (22 channels total)
â”œâ”€â”€ Conv Block 1: 32 filters + SE Block + MaxPool
â”œâ”€â”€ Conv Block 2: 64 filters + SE Block + MaxPool  
â”œâ”€â”€ Conv Block 3: 128 filters + SE Block + MaxPool
â”œâ”€â”€ Global Average Pooling
â”œâ”€â”€ FC Layer: 256 neurons + Dropout
â””â”€â”€ Output: 1 neuron (binary classification)
```

### Squeeze-and-Excitation (SE) Block
```
Input Features â†’ Global Average Pooling
â”œâ”€â”€ FC1: Reduction (r=4)
â”œâ”€â”€ ReLU
â”œâ”€â”€ FC2: Expansion
â”œâ”€â”€ Sigmoid
â””â”€â”€ Channel-wise multiplication with input
```

## ğŸ“ Project Structure

```
eye_project/
â”œâ”€â”€ ğŸ“ dataset/
â”‚   â”œâ”€â”€ ğŸ“ control/              # Control subject images
â”‚   â”œâ”€â”€ ğŸ“ diabetic/             # Diabetic subject images
â”‚   â”œâ”€â”€ ğŸ“ testing/              # Test images set 1
â”‚   â”œâ”€â”€ ğŸ“ testing1/             # Test images set 2
â”‚   â”œâ”€â”€ ğŸ“ masks/                # Manual masks for training
â”‚   â”œâ”€â”€ ğŸ“ pancreas_masks_for_training/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ control/          # Pancreatic masks for control
â”‚   â”‚   â””â”€â”€ ğŸ“ diabetic/         # Pancreatic masks for diabetic
â”‚   â””â”€â”€ ğŸ“ pancreas_masks_for_testing/
â”‚       â”œâ”€â”€ ğŸ“ testing/          # Test pancreatic masks
â”‚       â””â”€â”€ ğŸ“ testing1/         # Test pancreatic masks
â”‚
â”œâ”€â”€ ğŸ“ test_results_masks/       # Generated iris masks
â”‚   â”œâ”€â”€ ğŸ“ control/
â”‚   â”œâ”€â”€ ğŸ“ diabetic/
â”‚   â”œâ”€â”€ ğŸ“ testing/
â”‚   â””â”€â”€ ğŸ“ testing1/
â”‚
â”œâ”€â”€ ğŸ“ performance_analysis/     # Performance evaluation results
â”‚   â”œâ”€â”€ ğŸ“ confusion_matrices/   # Confusion matrix visualizations
â”‚   â”œâ”€â”€ ğŸ“ sample_results/       # Sample prediction results
â”‚   â””â”€â”€ ğŸ“ metrics/              # Performance metrics and plots
â”‚
â”œâ”€â”€ ğŸ“ generated_figures/        # Generated visualizations
â”œâ”€â”€ ğŸ“ gradcam_outputs/          # Grad-CAM heatmaps
â”œâ”€â”€ ğŸ“ heatmaps_output/          # Additional heatmaps
â”œâ”€â”€ ğŸ“ test_data/                # Test data
â””â”€â”€ ğŸ“ test_results/             # Test results
    â”œâ”€â”€ ğŸ“ control/
    â””â”€â”€ ğŸ“ diabetic/

# Core Python Scripts
â”œâ”€â”€ ğŸ maskstrain.py             # Phase 1: Iris segmentation training
â”œâ”€â”€ ğŸ maskspredict.py           # Phase 1: Iris mask generation
â”œâ”€â”€ ğŸ pancreaticmasks.py        # Phase 2: Pancreatic ROI extraction
â”œâ”€â”€ ğŸ cnntrain.py               # Phase 2: Classification training
â”œâ”€â”€ ğŸ cnnpredict.py             # Phase 2: Diabetic classification
â”œâ”€â”€ ğŸ metrices.py               # Model evaluation metrics
â”œâ”€â”€ ğŸ evaluate.py               # Model evaluation script
â”œâ”€â”€ ğŸ images.py                 # Visualization generation
â”œâ”€â”€ ğŸ rgbtograycrop.py          # Image preprocessing utilities
â”œâ”€â”€ ğŸ test.py                   # Testing utilities
â”œâ”€â”€ ğŸ performance_analysis_generator.py  # Performance analysis

# Model Files
â”œâ”€â”€ ğŸ·ï¸ best_iris_model_2class.pth      # 2-class iris segmentation model
â”œâ”€â”€ ğŸ·ï¸ best_iris_model_3class.pth      # 3-class iris segmentation model
â”œâ”€â”€ ğŸ·ï¸ best_f1_model_fold_1.pth        # Classification model fold 1
â”œâ”€â”€ ğŸ·ï¸ best_f1_model_fold_2.pth        # Classification model fold 2
â”œâ”€â”€ ğŸ·ï¸ best_f1_model_fold_3.pth        # Classification model fold 3
â”œâ”€â”€ ğŸ·ï¸ best_f1_model_fold_4.pth        # Classification model fold 4
â””â”€â”€ ğŸ·ï¸ best_f1_model_fold_5.pth        # Classification model fold 5

# Data Files
â”œâ”€â”€ ğŸ“„ annotations.csv           # Image annotations
â”œâ”€â”€ ğŸ“„ evaluation_results.csv    # Model evaluation results
â”œâ”€â”€ ğŸ“„ prediction_results.csv    # Prediction results
â”œâ”€â”€ ğŸ“„ cross_validation_chart.json  # Cross-validation results
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â””â”€â”€ ğŸ“„ README.md                 # This file
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended)
- Minimum 8GB RAM
- 10GB storage space

### Step 1: Clone Repository
```bash
git clone <repository-url>
cd eye_project
```

### Step 2: Create Virtual Environment
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Dependencies
```
torch>=2.0.0
torchvision>=0.15.0
opencv-python>=4.8.0
albumentations>=1.3.0
segmentation-models-pytorch>=0.3.3
scikit-learn>=1.3.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
torchmetrics>=1.0.0
grad-cam>=1.4.8
```

## ğŸš€ Usage Instructions

### Option 1: Complete Pipeline (Recommended)
If you want to run the entire pipeline from scratch:

#### Phase 1: Iris Segmentation
```bash
# Step 1: Train iris segmentation model
python maskstrain.py

# Step 2: Generate iris masks for all images
python maskspredict.py
```

#### Phase 2: Classification
```bash
# Step 3: Generate pancreatic region masks
python pancreaticmasks.py

# Step 4: Train classification model
python cnntrain.py

# Step 5: Run predictions
python cnnpredict.py
```

### Option 2: Using Pre-trained Models (Quick Start)
If you want to use the existing trained models:

```bash
# Generate predictions using pre-trained models
python cnnpredict.py

# Or run evaluation
python metrices.py
```

### Option 3: Performance Analysis
```bash
# Generate comprehensive performance analysis
python performance_analysis_generator.py
```

## ğŸ“ˆ Performance Analysis

The project includes comprehensive performance analysis tools that generate:

### 1. Confusion Matrix
- Visual representation of classification results
- True Positives, False Positives, True Negatives, False Negatives
- Accuracy, Sensitivity, Specificity metrics

### 2. ROC Curve Analysis
- Receiver Operating Characteristic curve
- Area Under Curve (AUC) calculation
- Optimal threshold determination

### 3. Probability Distribution Analysis
- Histogram of prediction probabilities
- Box plots by class
- Violin plots for distribution shape
- Cumulative distribution functions

### 4. Sample Results Table
- 10 representative samples with results
- Correct and incorrect predictions
- Confidence levels (Low/Medium/High)
- Patient IDs and image pairs

### 5. Cross-Validation Results
- 5-fold cross-validation performance
- Box plots of metric distributions
- Mean and standard deviation reporting

## ğŸ¯ Results

### Model Performance Metrics

#### Cross-Validation Results (5-Fold)
| Metric | Mean Â± Std | Range |
|--------|------------|-------|
| **Accuracy** | 92.4% Â± 0.3% | 92.0% - 92.8% |
| **Sensitivity** | 93.1% Â± 0.5% | 92.5% - 93.7% |
| **Specificity** | 91.7% Â± 0.2% | 91.5% - 92.0% |
| **F1-Score** | 92.5% Â± 0.3% | 92.1% - 92.9% |

#### Overall Test Performance
- **Total Samples**: 148 patients
- **Control Subjects**: 65 patients  
- **Diabetic Subjects**: 83 patients
- **Overall Accuracy**: 92.6%
- **AUC-ROC**: 0.965

### Key Findings
1. **High Sensitivity**: 93.1% - Excellent detection of diabetic cases
2. **High Specificity**: 91.7% - Low false positive rate for control subjects
3. **Balanced Performance**: Consistent results across both classes
4. **Robust Model**: Low standard deviation across folds indicates stability

## ğŸ”§ Technical Specifications

### Hardware Requirements
- **GPU**: NVIDIA GTX 1060 or better (6GB+ VRAM)
- **CPU**: Intel i5 or AMD Ryzen 5 equivalent
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: 10GB free space

### Software Environment
- **OS**: Windows 10/11, Ubuntu 18.04+, macOS 10.15+
- **Python**: 3.8, 3.9, 3.10, 3.11
- **CUDA**: 11.0+ (for GPU acceleration)

### Model Specifications
- **Segmentation Model Size**: ~25MB
- **Classification Model Size**: ~15MB per fold (75MB total)
- **Training Time**: ~2-4 hours per phase (GPU)
- **Inference Time**: ~0.5 seconds per image pair

### Input/Output Specifications
- **Input Image Format**: JPEG, PNG
- **Input Resolution**: Variable (auto-resized)
- **Output Format**: CSV results, PNG visualizations
- **Batch Processing**: Supported for large datasets

## ğŸ“ Citation

If you use this work in your research, please cite:

```bibtex
@misc{diabetes_iris_detection_2024,
  title={Diabetes Detection from Iris Images using Deep Learning},
  author={[Your Name]},
  year={2024},
  note={GitHub repository},
  url={[Repository URL]}
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add new feature'`)
4. Push to branch (`git push origin feature/improvement`)
5. Create Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   - Reduce batch size in config files
   - Use CPU mode by setting `DEVICE = "cpu"`

2. **Missing Dependencies**
   - Ensure all packages in requirements.txt are installed
   - Use virtual environment to avoid conflicts

3. **Path Errors**
   - Verify dataset directory structure matches documentation
   - Use absolute paths if relative paths fail

4. **Model Loading Errors**
   - Ensure model files are not corrupted
   - Check device compatibility (CPU/GPU)

### Support

For issues and questions:
- Check existing issues in the repository
- Create new issue with detailed description
- Include error logs and system specifications

## ğŸ“ Contact

- **Author**: [Your Name]
- **Email**: [Your Email]
- **Institution**: [Your Institution]
- **Date**: October 2024

---

**Note**: This project is for research purposes. Clinical validation required before medical use.